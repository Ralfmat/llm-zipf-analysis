# LLM Zipf Analysis

This project investigates whether text generated by Large Language Models (LLMs) follows **Zipf's Law**â€”a statistical law stating that the frequency of any word is inversely proportional to its rank in the frequency table.

The goal is to determine if LLMs, at various temperature settings and creative tasks, statistically resemble human writing or if they exhibit detectable statistical "fingerprints" (e.g., lower vocabulary richness, different power-law exponents).

## ðŸ§ª Research Methodology

### 1. Data Sources
We compare AI-generated text against established human datasets across two genres:
* **Encyclopedic/Academic:**
    * **Human:** `WikiText-103` ([Wikipedia articles](https://huggingface.co/datasets/Salesforce/wikitext)).
    * **AI:** Llama 3.3 70b & Gemini 2.5 Pro generating encyclopedic articles (e.g., "The History of the Ottoman Empire").
* **Creative Fiction:**
    * **Human:** Frank Herbert's *Dune*.
    * **AI:** Llama 3.3 70b & Gemini 2.5 Pro generating sci-fi novel chapters based on specific prompts.

### 2. Variables
* **Models:** Gemini 2.5 Pro, Llama 3.3 70b.
* **Temperature:** Analyzed impact of temperature settings (`0.2`, `1.0`, `1.5`) on vocabulary distribution.
* **Metrics:**
    * **Alpha ($\alpha$):** The scaling parameter of the power-law distribution (calculated using the `powerlaw` library).
    * **Unique Word Count:** A measure of lexical diversity.
    * **Zipf Plots:** Log-log plots comparing word rank vs. frequency.

---

## ðŸ“‚ Project Structure

### `src/` (Source Code)

#### **Data Generation**
* **`gemini_generator.py`**: Uses the Google GenAI SDK to generate academic/encyclopedic essays. It iterates through specific topics and temperatures to build a large corpus.
* **`llama_generator.py`**: Uses the Groq SDK (Llama 3.3) to generate creative fiction. It uses complex prompting to simulate "high literary fiction" in a sci-fi setting.

#### **Analysis & Visualization**
* **`ai_text_analysis.py`**: The main analysis script for the **Encyclopedic** comparison.
    * Loads AI text and human WikiText.
    * Performs random sampling of human text to match the AI text length.
    * Calculates and plots the Zipf distribution and Alpha parameters side-by-side.
* **`book_comparasion.py`**: The main analysis script for the **Fiction** comparison.
    * Compares AI-generated novel text against *Dune*.
    * Ensures sample sizes are identical for fair statistical comparison.
    * Visualizes the "Ideal Zipf" slope vs. Human vs. AI.
* **`book_analysis.py`**: A utility script to analyze a single text file in isolation. Useful for quick checks of a specific model output.

---

## ðŸ“Š Key Findings

* **Human Text:** typically exhibits an Alpha ($\alpha$) close to the "Ideal Zipf" value (approx ~2.0) with a "long tail" of unique words.
* **AI Text:** Depending on temperature, AI often produces a "steeper" curve or fewer unique words (lower lexical diversity) than human authors, especially at lower temperatures (0.2). High temperatures (1.5) may artificially inflate diversity but can degrade coherence.
